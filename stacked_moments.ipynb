{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmin import minimize as torchmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "\n",
    "from jax.scipy.optimize import minimize as jaxmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.84995148,  0.34576802,  0.35638789,  0.89451017, -0.15926814,\n",
       "       -0.00526948,  0.01192015,  0.02078758])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dgp(n=500, k=3, reg=False, torchout = False):\n",
    "    X = np.random.normal(0, 1, n * k).reshape(n, k)\n",
    "    Y0 = X[:, 0] + X[:, 0] ** 2 + np.random.uniform(-0.5, 0.5, n)\n",
    "    Y1 = X[:, 1] + X[:, 1] ** 2 + np.random.uniform(-1, 1, n)\n",
    "    Z = np.random.binomial(1, 0.6, n)\n",
    "    Y = Y0 * (1 - Z) + Y1 * Z\n",
    "    if torchout:\n",
    "        return torch.tensor(np.c_[Y, Z, X])\n",
    "    return np.c_[Y, Z, X]\n",
    "\n",
    "def linreg(data):\n",
    "    Y, Z, X = data[:, 0], data[:, 1], data[:, 2:]\n",
    "    XX = sm.add_constant(np.c_[Z, X, Z[:, None] * X.mean(axis = 0)])\n",
    "    model = sm.OLS(Y, XX).fit()\n",
    "    return model.params\n",
    "\n",
    "linreg(dgp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Y_i = \\alpha + \\tau W_i + X_i'\\beta + W_i \\tilde{X}_i'\\gamma + \\epsilon_i\n",
    "$$\n",
    "\n",
    "where $\\tilde{X}_i = X_i - \\bar{X}$ is a centered version of $X_i$. The goal is to estimate $\\tau$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moment_cond_cent(theta, data):\n",
    "    Z, Y, X = data[:, 1], data[:, 0], data[:, 2:]\n",
    "    n, p = X.shape\n",
    "    mu, beta = theta[:p], theta[p:]\n",
    "    Xcent = X - mu\n",
    "    ones = torch.ones(n, 1, device=data.device)\n",
    "    Xtilde = torch.cat([ones, Z.view(-1, 1), X, Z.view(-1, 1) * Xcent], dim=1)\n",
    "    resid = (Y - torch.matmul(Xtilde, beta)).view(-1, 1)\n",
    "    m = Xtilde * resid\n",
    "    return torch.cat([m, Xcent], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.004  0.105  0.291  0.403 -0.    -0.006]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.976,  0.106,  0.717, -0.082, -0.666,  0.753])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dgp(n = 1_000, k = 2, torchout=True)\n",
    "print(np.round(linreg(data.numpy()), 3))\n",
    "# m-estimation\n",
    "k = data.shape[1]\n",
    "theta_init = torch.tensor(np.random.rand((k-1)*2 +(k-2)))\n",
    "\n",
    "def loss(theta):\n",
    "    m = moment_cond_cent(theta, data)\n",
    "    return torch.sum(m.mean(axis=0) ** 2)\n",
    "\n",
    "params = torchmin(loss, x0 = theta_init, method=\"l-bfgs\")\n",
    "params.x[2:].numpy().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moment_cond_jax(theta, data):\n",
    "    Z, Y, X = jnp.array(data[:, 1]), jnp.array(data[:, 0]), jnp.array(data[:, 2:])\n",
    "    n, p = X.shape\n",
    "    mu, beta = theta[:p], theta[p:]\n",
    "    Xcent = X - mu\n",
    "    Xtilde = jnp.c_[np.ones(n), Z, X, Z[:, None] * Xcent]\n",
    "    resid = (Y - Xtilde @ beta)[:, None]\n",
    "    m = Xtilde * resid\n",
    "    return jnp.c_[m, Xcent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_objective(theta, data):\n",
    "    moments = moment_cond_jax(theta, data)\n",
    "    return np.sum(moments.mean(axis=0) ** 2)\n",
    "\n",
    "@jax.jit\n",
    "def optimize_gmm(theta_init, data):\n",
    "    return jaxmin(lambda theta: gmm_objective(theta, data), theta_init, method=\"BFGS\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.952  0.13   0.468  0.584  0.002 -0.005]\n",
      "[ 0.90300006  0.13900001  0.94600004  0.003      -0.79800004  0.9710001 ]\n"
     ]
    }
   ],
   "source": [
    "data = dgp(n = 1_000, k = 2, torchout=False)\n",
    "print(np.round(linreg(data), 3))\n",
    "\n",
    "k = data.shape[1]\n",
    "theta_init = np.random.rand((k-1)*2 +(k-2))\n",
    "\n",
    "print(np.round(optimize_gmm(theta_init, data).x[2:], 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metrics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
